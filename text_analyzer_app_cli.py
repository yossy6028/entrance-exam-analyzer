#!/usr/bin/env python3
"""
å…¥è©¦å•é¡Œãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆCLIç‰ˆï¼‰
ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ â†’ å­¦æ ¡åãƒ»å¹´åº¦ã‚’æŠ½å‡ºãƒ»ç¢ºèª â†’ åˆ†æ â†’ Excelå‡ºåŠ›
"""

import os
import sys
import re
from pathlib import Path
import pandas as pd
from datetime import datetime

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(str(Path(__file__).parent))
from modules.text_analyzer import TextAnalyzer
from modules.pattern_extractor import PatternExtractor
from modules.excel_writer import ExcelWriter


class TextAnalyzerCLI:
    """ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆCLIç‰ˆï¼‰"""
    
    def __init__(self):
        # BunkoOCRçµæœãƒ•ã‚©ãƒ«ãƒ€
        self.bunko_results_dir = Path.home() / "Library/Mobile Documents/iCloud~info~lithium03~bunkoOCR/Documents/Results"
        self.text_files = []
        self.current_text = ""
        
    def clear_screen(self):
        """ç”»é¢ã‚’ã‚¯ãƒªã‚¢"""
        os.system('clear' if os.name == 'posix' else 'cls')
        
    def print_header(self):
        """ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¡¨ç¤º"""
        print("=" * 60)
        print("     å…¥è©¦å•é¡Œãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚·ã‚¹ãƒ†ãƒ ")
        print("     Text Analysis System")
        print("=" * 60)
        print()
        
    def select_text_files(self):
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ"""
        print("ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«é¸æŠã€‘")
        print("1. æ‰‹å‹•ã§ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›")
        print("2. BunkoOCRçµæœã‹ã‚‰é¸æŠ")
        print("3. éå»å•ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰æ¤œç´¢")
        print("-" * 40)
        
        choice = input("é¸æŠæ–¹æ³• (1-3): ")
        
        if choice == "1":
            self.manual_file_selection()
        elif choice == "2":
            self.select_from_bunko()
        elif choice == "3":
            self.search_from_kakomon()
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
            return False
            
        return len(self.text_files) > 0
        
    def manual_file_selection(self):
        """æ‰‹å‹•ã§ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›"""
        print("\nãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        print("è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯æ”¹è¡Œã§åŒºåˆ‡ã£ã¦å…¥åŠ›ï¼ˆç©ºè¡Œã§çµ‚äº†ï¼‰")
        
        files = []
        while True:
            path = input("ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: ").strip()
            if not path:
                break
                
            file_path = Path(path)
            if file_path.exists() and file_path.suffix == '.txt':
                files.append(file_path)
                print(f"âœ… {file_path.name}")
            else:
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")
                
        self.text_files = files
        
    def select_from_bunko(self):
        """BunkoOCRçµæœã‹ã‚‰é¸æŠ"""
        if not self.bunko_results_dir.exists():
            print("âŒ BunkoOCRçµæœãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
            
        # æœ€æ–°ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’è¡¨ç¤º
        folders = sorted(self.bunko_results_dir.iterdir(), 
                        key=lambda p: p.stat().st_mtime, reverse=True)
        
        if not folders:
            print("âŒ BunkoOCRçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
            
        print("\nã€BunkoOCRçµæœä¸€è¦§ã€‘")
        print("-" * 60)
        
        folder_list = []
        for i, folder in enumerate(folders[:20], 1):  # æœ€æ–°20ä»¶
            timestamp = datetime.fromtimestamp(folder.stat().st_mtime)
            text_files = list(folder.glob("text*.txt"))
            if text_files:
                print(f"{i:2d}. {timestamp.strftime('%Y-%m-%d %H:%M')} - {folder.name}")
                print(f"    ({len(text_files)}å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«)")
                folder_list.append(folder)
                
        print("-" * 60)
        
        try:
            choice = int(input("\nç•ªå·ã‚’é¸æŠ (1-{}): ".format(len(folder_list))))
            if 1 <= choice <= len(folder_list):
                selected_folder = folder_list[choice - 1]
                self.text_files = sorted(selected_folder.glob("text*.txt"))
                print(f"\nâœ… é¸æŠ: {selected_folder.name}")
            else:
                print("âŒ ç„¡åŠ¹ãªç•ªå·ã§ã™")
        except ValueError:
            print("âŒ æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            
    def search_from_kakomon(self):
        """éå»å•ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰æ¤œç´¢"""
        kakomon_dir = Path.home() / "Desktop/01_ä»•äº‹ (Work)/ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®¶åº­æ•™å¸«è³‡æ–™/éå»å•"
        
        if not kakomon_dir.exists():
            print("âŒ éå»å•ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
            
        print("\næ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ï¼ˆä¾‹ï¼šå¥³å­å­¦é™¢ 2023ï¼‰")
        keyword = input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ")
        
        if not keyword:
            return
            
        print("\næ¤œç´¢ä¸­...")
        found_files = []
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        for txt_file in kakomon_dir.glob("**/*.txt"):
            if keyword.lower() in str(txt_file).lower():
                found_files.append(txt_file)
                
        if found_files:
            print(f"\n{len(found_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            for i, file in enumerate(found_files[:10], 1):  # æœ€å¤§10ä»¶è¡¨ç¤º
                print(f"{i:2d}. {file.relative_to(kakomon_dir)}")
                
            try:
                choice = int(input("\nç•ªå·ã‚’é¸æŠ (1-{}): ".format(min(10, len(found_files)))))
                if 1 <= choice <= min(10, len(found_files)):
                    self.text_files = [found_files[choice - 1]]
                    print(f"\nâœ… é¸æŠ: {self.text_files[0].name}")
            except ValueError:
                print("âŒ æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
    def extract_info(self):
        """å­¦æ ¡åã¨å¹´åº¦ã‚’æŠ½å‡º"""
        if not self.text_files:
            return None, None
            
        # æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        try:
            self.current_text = self.text_files[0].read_text(encoding='utf-8')
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None, None
            
        file_path = str(self.text_files[0])
        
        # å­¦æ ¡åã®æŠ½å‡º
        school_patterns = [
            r'(é–‹æˆ|éº»å¸ƒ|æ­¦è”µ|æ¡œè”­|å¥³å­å­¦é™¢|é›™è‘‰|æ¸‹è°·æ•™è‚²å­¦åœ’æ¸‹è°·|æ¸‹æ¸‹|æ…¶æ‡‰ç¾©å¡¾|æ—©ç¨²ç”°å®Ÿæ¥­)',
            r'(\w+ä¸­å­¦æ ¡)',
            r'(\w+ä¸­ç­‰éƒ¨)',
        ]
        
        school = ""
        for pattern in school_patterns:
            match = re.search(pattern, file_path)
            if match:
                school = match.group(1)
                if 'ä¸­å­¦æ ¡' not in school and 'ä¸­ç­‰éƒ¨' not in school:
                    school += 'ä¸­å­¦æ ¡'
                break
                
        # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚‚å­¦æ ¡åã‚’æ¢ã™
        if not school:
            for pattern in school_patterns:
                match = re.search(pattern, self.current_text[:500])
                if match:
                    school = match.group(1)
                    if 'ä¸­å­¦æ ¡' not in school and 'ä¸­ç­‰éƒ¨' not in school:
                        school += 'ä¸­å­¦æ ¡'
                    break
                    
        # å¹´åº¦ã®æŠ½å‡º
        year_patterns = [
            r'(20\d{2})å¹´',
            r'(20\d{2})',
            r'(\d{2})å¹´åº¦',
            r'ä»¤å’Œ(\d+)å¹´',
            r'å¹³æˆ(\d+)å¹´',
        ]
        
        year = ""
        for pattern in year_patterns:
            match = re.search(pattern, file_path)
            if match:
                if 'ä»¤å’Œ' in pattern:
                    year = str(2018 + int(match.group(1)))
                elif 'å¹³æˆ' in pattern:
                    year = str(1988 + int(match.group(1)))
                else:
                    year = match.group(1)
                    if len(year) == 2:
                        year = '20' + year
                break
                
        # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚‚å¹´åº¦ã‚’æ¢ã™
        if not year:
            for pattern in year_patterns:
                match = re.search(pattern, self.current_text[:500])
                if match:
                    if 'ä»¤å’Œ' in pattern:
                        year = str(2018 + int(match.group(1)))
                    elif 'å¹³æˆ' in pattern:
                        year = str(1988 + int(match.group(1)))
                    else:
                        year = match.group(1)
                        if len(year) == 2:
                            year = '20' + year
                    break
                    
        return school, year
        
    def confirm_info(self, school, year):
        """æŠ½å‡ºã—ãŸæƒ…å ±ã‚’ç¢ºèª"""
        print("\nã€æŠ½å‡ºã•ã‚ŒãŸæƒ…å ±ã€‘")
        print("-" * 40)
        print(f"å­¦æ ¡å: {school if school else 'ä¸æ˜'}")
        print(f"å¹´åº¦: {year if year else 'ä¸æ˜'}å¹´")
        print("-" * 40)
        
        # ä¿®æ­£ãŒå¿…è¦ã‹ç¢ºèª
        print("\næƒ…å ±ã¯æ­£ã—ã„ã§ã™ã‹ï¼Ÿ")
        print("1. æ­£ã—ã„")
        print("2. ä¿®æ­£ã™ã‚‹")
        
        choice = input("é¸æŠ (1-2): ")
        
        if choice == "2":
            # æ‰‹å‹•å…¥åŠ›
            print("\næ­£ã—ã„æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            school = input(f"å­¦æ ¡å [{school}]: ").strip() or school
            year = input(f"å¹´åº¦ [{year}]: ").strip() or year
            
        return school, year
        
    def execute_analysis(self, school_name, year):
        """åˆ†æã‚’å®Ÿè¡Œ"""
        try:
            print("\nğŸ“Š åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
            if len(self.text_files) > 1:
                print(f"   {len(self.text_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆä¸­...")
                combined_text = ""
                for txt_file in sorted(self.text_files):
                    combined_text += txt_file.read_text(encoding='utf-8')
                    combined_text += "\n\n"
            else:
                combined_text = self.text_files[0].read_text(encoding='utf-8')
                
            # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
            print("   ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æä¸­...")
            analyzer = TextAnalyzer()
            result = analyzer.analyze_exam_structure(combined_text)
            
            # å‡ºå…¸æƒ…å ±ã‚’æŠ½å‡º
            print("   å‡ºå…¸æƒ…å ±ã‚’æŠ½å‡ºä¸­...")
            extractor = PatternExtractor()
            sources = extractor.extract_sources(combined_text)
            
            # çµæœã«æƒ…å ±ã‚’è¿½åŠ 
            result['school_name'] = school_name
            result['year'] = year
            result['sources'] = sources
            
            # åˆ†æçµæœã‚’è¡¨ç¤º
            print("\nã€åˆ†æçµæœã€‘")
            print("-" * 60)
            print(f"ç·æ–‡å­—æ•°: {result.get('total_characters', 0):,}æ–‡å­—")
            print(f"å¤§å•æ•°: {len(result.get('sections', []))}å•")
            print(f"ç·è¨­å•æ•°: {len(result.get('questions', []))}å•")
            print("-" * 60)
            
            # å¤§å•ã”ã¨ã®æƒ…å ±
            for i, section in enumerate(result.get('sections', []), 1):
                print(f"\nå¤§å•{i}:")
                print(f"  æ–‡å­—æ•°: {len(section.get('text', '')):,}æ–‡å­—")
                print(f"  è¨­å•æ•°: {section.get('question_count', 0)}å•")
                
            # Excelã«ä¿å­˜
            print("\nğŸ’¾ Excelãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ä¸­...")
            self.save_to_database(result, school_name, year)
            
            print("\nâœ… åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            print(f"   çµæœã¯ entrance_exam_database.xlsx ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
            
            return True
            
        except Exception as e:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return False
            
    def save_to_database(self, analysis_result, school_name, year):
        """Excelãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        db_filename = "entrance_exam_database.xlsx"
        
        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        try:
            existing_sheets = pd.ExcelFile(db_filename, engine='openpyxl').sheet_names
        except FileNotFoundError:
            existing_sheets = []
            
        # ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        data_row = self.prepare_data_row(analysis_result, school_name, year)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        new_df = pd.DataFrame([data_row])
        
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with pd.ExcelWriter(db_filename, engine='openpyxl', 
                           mode='a' if existing_sheets else 'w', 
                           if_sheet_exists='replace') as writer:
            if school_name in existing_sheets:
                # æ—¢å­˜ã‚·ãƒ¼ãƒˆã«è¿½åŠ 
                existing_df = pd.read_excel(db_filename, sheet_name=school_name)
                existing_df['å¹´åº¦'] = pd.to_numeric(existing_df['å¹´åº¦'], errors='coerce')
                
                # åŒã˜å¹´åº¦ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°æ›´æ–°
                year_int = int(year)
                if year_int in existing_df['å¹´åº¦'].values:
                    existing_df = existing_df[existing_df['å¹´åº¦'] != year_int]
                    
                combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                combined_df = combined_df.sort_values('å¹´åº¦')
            else:
                combined_df = new_df
                
            combined_df.to_excel(writer, sheet_name=school_name, index=False)
            
    def prepare_data_row(self, analysis_result, school_name, year):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç”¨ã®ãƒ‡ãƒ¼ã‚¿è¡Œã‚’æº–å‚™"""
        data_row = {
            'å¹´åº¦': int(year),
            'ç·è¨­å•æ•°': len(analysis_result.get('questions', [])),
            'ç·æ–‡å­—æ•°': analysis_result.get('total_characters', 0),
            'å¤§å•æ•°': len(analysis_result.get('sections', []))
        }
        
        # å„å¤§å•ã®ãƒ‡ãƒ¼ã‚¿
        for i, section in enumerate(analysis_result.get('sections', []), 1):
            # ã‚¸ãƒ£ãƒ³ãƒ«ã¨ãƒ†ãƒ¼ãƒã‚’åˆ¤å®š
            genre, theme = self.determine_genre_and_theme(section.get('text', ''))
            
            # å‡ºå…¸æƒ…å ±ã‚’å–å¾—
            source = next((s for s in analysis_result.get('sources', []) 
                          if s.get('section') == i), {})
            
            data_row[f'å¤§å•{i}_ã‚¸ãƒ£ãƒ³ãƒ«'] = genre
            data_row[f'å¤§å•{i}_ãƒ†ãƒ¼ãƒ'] = theme
            data_row[f'å¤§å•{i}_è‘—è€…'] = source.get('author', 'ä¸æ˜')
            data_row[f'å¤§å•{i}_ä½œå“'] = source.get('title', 'ä¸æ˜')
            data_row[f'å¤§å•{i}_è¨­å•æ•°'] = section.get('question_count', 0)
            data_row[f'å¤§å•{i}_æ–‡å­—æ•°'] = len(section.get('text', ''))
            
        # è¨­å•ã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ
        for q_type, count in analysis_result.get('question_types', {}).items():
            data_row[f'{q_type}_å•é¡Œæ•°'] = count
            
        return data_row
        
    def determine_genre_and_theme(self, text):
        """æ–‡ç« ã®ã‚¸ãƒ£ãƒ³ãƒ«ã¨ãƒ†ãƒ¼ãƒã‚’åˆ¤å®š"""
        text_sample = text[:1000] if len(text) > 1000 else text
        
        # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¤å®š
        if any(word in text_sample for word in ['å°èª¬', 'ç‰©èª', 'ã€Œ', 'ã€', 'ã¨è¨€ã£ãŸ']):
            genre = 'å°èª¬ãƒ»ç‰©èª'
        elif any(word in text_sample for word in ['è©•è«–', 'è«–èª¬', 'ã«ã¤ã„ã¦', 'ã¨ã„ã†']):
            genre = 'è©•è«–ãƒ»è«–èª¬'
        elif any(word in text_sample for word in ['éšç­†', 'ã‚¨ãƒƒã‚»ã‚¤', 'ç§ã¯']):
            genre = 'éšç­†ãƒ»ã‚¨ãƒƒã‚»ã‚¤'
        else:
            genre = 'è©•è«–ãƒ»è«–èª¬'
            
        # ãƒ†ãƒ¼ãƒåˆ¤å®š
        if any(word in text_sample for word in ['å‹æƒ…', 'å®¶æ—', 'æˆé•·']):
            theme = 'äººé–“é–¢ä¿‚ãƒ»æˆé•·'
        elif any(word in text_sample for word in ['è‡ªç„¶', 'ç’°å¢ƒ', 'ç”Ÿç‰©']):
            theme = 'è‡ªç„¶ãƒ»ç’°å¢ƒ'
        elif any(word in text_sample for word in ['ç¤¾ä¼š', 'æ–‡åŒ–', 'æ­´å²']):
            theme = 'ç¤¾ä¼šãƒ»æ–‡åŒ–'
        elif any(word in text_sample for word in ['ç§‘å­¦', 'æŠ€è¡“', 'AI']):
            theme = 'ç§‘å­¦ãƒ»æŠ€è¡“'
        else:
            theme = 'ä¸€èˆ¬'
            
        return genre, theme
        
    def run(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        self.clear_screen()
        self.print_header()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
        if not self.select_text_files():
            print("\nãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return
            
        print(f"\nâœ… {len(self.text_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã—ãŸ")
        for file in self.text_files[:5]:  # æœ€åˆã®5å€‹ã‚’è¡¨ç¤º
            print(f"   - {file.name}")
        if len(self.text_files) > 5:
            print(f"   ... ä»–{len(self.text_files) - 5}å€‹")
            
        # æƒ…å ±æŠ½å‡º
        print("\nğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºä¸­...")
        school, year = self.extract_info()
        
        # æƒ…å ±ç¢ºèª
        school, year = self.confirm_info(school, year)
        
        if not school or not year:
            print("\nâŒ å­¦æ ¡åã¾ãŸã¯å¹´åº¦ãŒä¸æ˜ã§ã™")
            return
            
        # æœ€çµ‚ç¢ºèª
        print("\n" + "=" * 60)
        print("ã€åˆ†æå†…å®¹ã®ç¢ºèªã€‘")
        print(f"å­¦æ ¡: {school}")
        print(f"å¹´åº¦: {year}å¹´")
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(self.text_files)}å€‹")
        print("=" * 60)
        
        confirm = input("\nã“ã®å†…å®¹ã§åˆ†æã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
        if confirm.lower() != 'y':
            print("\nåˆ†æã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return
            
        # åˆ†æå®Ÿè¡Œ
        self.execute_analysis(school, year)
        
        print("\nå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦çµ‚äº†ã—ã¦ãã ã•ã„...")
        input()


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    app = TextAnalyzerCLI()
    app.run()


if __name__ == "__main__":
    main()