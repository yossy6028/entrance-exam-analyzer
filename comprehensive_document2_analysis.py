#!/usr/bin/env python3
"""
è–å…‰å­¦é™¢2025å¹´å›½èª æ–‡ç« 2ï¼ˆæ°¸äº•ä½³å­ï¼‰åŒ…æ‹¬çš„åˆ†æ
æ­£ç¢ºãªè¨­å•æŠ½å‡ºã¨ä¸æ•´åˆæ¤œè¨¼
"""

import re
from typing import List, Dict, Tuple

def main():
    """ãƒ¡ã‚¤ãƒ³åˆ†æé–¢æ•°"""
    with open('/Users/yoshiikatsuhiko/Desktop/01_ä»•äº‹ (Work)/ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®¶åº­æ•™å¸«è³‡æ–™/éå»å•/è–å…‰å­¦é™¢/kokugo-mondai (1).ocr.txt', 'r', encoding='utf-8') as f:
        full_text = f.read()
    
    print("=== è–å…‰å­¦é™¢2025å¹´å›½èª æ–‡ç« 2ï¼ˆæ°¸äº•ä½³å­ï¼‰åŒ…æ‹¬çš„è¨­å•åˆ†æ ===")
    print()
    
    # æ°¸äº•ä½³å­æ–‡ç« ã®è¨­å•ã‚’æ­£ç¢ºã«æŠ½å‡º
    questions = extract_document2_questions_precise(full_text)
    
    print("=== å„è¨­å•ã®è©³ç´°åˆ†æ ===")
    print()
    
    analysis_results = []
    for q_num in ['å•ä¸€', 'å•äºŒ', 'å•ä¸‰', 'å•å››', 'å•äº”', 'å•å…­', 'å•ä¸ƒ', 'å•å…«']:
        if q_num in questions:
            analysis = analyze_question_precisely(questions[q_num])
            analysis_results.append({
                'number': q_num,
                'type': analysis['type'],
                'details': analysis['details'],
                'content': questions[q_num][:100] + "..." if len(questions[q_num]) > 100 else questions[q_num]
            })
            
            print(f"{q_num}: {analysis['type']} - {analysis['details']}")
            print(f"  å†…å®¹ä¾‹: {questions[q_num][:80]}...")
            print()
        else:
            print(f"{q_num}: è¨­å•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            print()
    
    # çµ±è¨ˆåˆ†æ
    type_summary = {}
    descriptive_questions = []
    choice_questions = []
    other_questions = []
    
    for result in analysis_results:
        q_type = result['type']
        if q_type not in type_summary:
            type_summary[q_type] = 0
        type_summary[q_type] += 1
        
        if 'è¨˜è¿°' in q_type:
            descriptive_questions.append(f"{result['number']}: {result['details']}")
        elif 'é¸æŠ' in q_type:
            choice_questions.append(f"{result['number']}: {result['details']}")
        else:
            other_questions.append(f"{result['number']}: {result['details']}")
    
    print("=== è¨­å•ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ ===")
    for q_type, count in type_summary.items():
        print(f"{q_type}: {count}å•")
    
    print()
    print("=== è¨˜è¿°å•é¡Œè©³ç´° ===")
    
    word_limit_desc = []
    no_word_limit_desc = []
    
    for desc in descriptive_questions:
        if 'å­—ä»¥å†…' in desc or 'ä¸€è¡Œ' in desc:
            word_limit_desc.append(desc)
        else:
            no_word_limit_desc.append(desc)
    
    print(f"æ–‡å­—æ•°æŒ‡å®šã‚ã‚Šè¨˜è¿°å•é¡Œ: {len(word_limit_desc)}å•")
    for q in word_limit_desc:
        print(f"  {q}")
    
    print(f"æ–‡å­—æ•°æŒ‡å®šãªã—è¨˜è¿°å•é¡Œ: {len(no_word_limit_desc)}å•")
    for q in no_word_limit_desc:
        print(f"  {q}")
    
    total_descriptive = len(descriptive_questions)
    print(f"è¨˜è¿°å•é¡Œç·æ•°: {total_descriptive}å•")
    
    print()
    print("=== é¸æŠå•é¡Œè©³ç´° ===")
    print(f"é¸æŠå•é¡Œç·æ•°: {len(choice_questions)}å•")
    for q in choice_questions:
        print(f"  {q}")
    
    if other_questions:
        print()
        print("=== ãã®ä»–å•é¡Œ ===")
        for q in other_questions:
            print(f"  {q}")
    
    # ä¸æ•´åˆæ¤œè¨¼
    print()
    print("=== ä¸æ•´åˆæ¤œè¨¼çµæœ ===")
    print("="*60)
    
    # å•é¡Œã®è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿ï¼ˆè¡¨é¡Œãªã©ï¼‰ã‹ã‚‰æ¨æ¸¬ã•ã‚Œã‚‹æ§‹æˆ
    expected_descriptive = 3  # è¡¨ç¤ºã§ã¯ã€Œè¨˜è¿°å•é¡Œ3å•ã€ã¨ãªã£ã¦ã„ã‚‹ã‚‰ã—ã„
    
    print(f"ã€æ¤œè¨¼ã€‘è¡¨ç¤ºä¸Šã®è¨˜è¿°å•é¡Œæ•°: {expected_descriptive}å•ï¼ˆæ¨å®šï¼‰")
    print(f"ã€å®Ÿéš›ã€‘å®Ÿéš›ã®è¨˜è¿°å•é¡Œæ•°: {total_descriptive}å•")
    
    if total_descriptive != expected_descriptive:
        print()
        print("ğŸš¨ ã€ä¸æ•´åˆã‚’ç™ºè¦‹ã€‘")
        print(f"è¡¨ç¤ºã§ã¯è¨˜è¿°å•é¡Œ{expected_descriptive}å•ã¨ã•ã‚Œã¦ã„ã‚‹ãŒã€å®Ÿéš›ã¯{total_descriptive}å•")
        
        if total_descriptive == 2 and len(word_limit_desc) == 2:
            print()
            print("ã€åŸå› åˆ†æã€‘")
            print("- 20å­—ä»¥å†…ã®è¨˜è¿°å•é¡Œ: 1å•ï¼ˆå•å››ï¼‰")
            print("- 80å­—ä»¥å†…ã®è¨˜è¿°å•é¡Œ: 1å•ï¼ˆå•å…«ï¼‰") 
            print("- åˆè¨ˆ: 2å•ï¼ˆæ–‡å­—æ•°æŒ‡å®šã‚ã‚Šè¨˜è¿°å•é¡Œã®ã¿ï¼‰")
            print("- è¡¨ç¤ºã®ã€Œ3å•ã€ã¯æ•°ãˆé–“é•ã„ã¾ãŸã¯ä»–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¨ã®æ··åŒã®å¯èƒ½æ€§")
            
        elif total_descriptive > expected_descriptive:
            print()
            print("ã€åŸå› åˆ†æã€‘")
            print(f"å®Ÿéš›ã®è¨˜è¿°å•é¡ŒãŒè¡¨ç¤ºã‚ˆã‚Šã‚‚{total_descriptive - expected_descriptive}å•å¤šã„")
            print("è¡¨ç¤ºã®æ›´æ–°ãŒå¿…è¦")
    else:
        print("âœ… ã€ä¸æ•´åˆãªã—ã€‘è¡¨ç¤ºã¨å®Ÿéš›ã®è¨˜è¿°å•é¡Œæ•°ãŒä¸€è‡´")
    
    print()
    print("=== ä¿®æ­£æ¡ˆ ===")
    print("="*30)
    
    if total_descriptive == 2 and len(word_limit_desc) == 2 and len(no_word_limit_desc) == 0:
        print("ã€æ¨å¥¨ä¿®æ­£ã€‘")
        print(f"è¡¨ç¤ºã‚’ã€Œè¨˜è¿°å•é¡Œ{total_descriptive}å•ã€ã«ä¿®æ­£")
        print("è©³ç´°: 20å­—ä»¥å†…1å•ã€80å­—ä»¥å†…1å•")
    elif total_descriptive > 2:
        print("ã€æ¨å¥¨ä¿®æ­£ã€‘")
        print(f"è¡¨ç¤ºã‚’ã€Œè¨˜è¿°å•é¡Œ{total_descriptive}å•ã€ã«ä¿®æ­£")
        print(f"  - æ–‡å­—æ•°æŒ‡å®šã‚ã‚Š: {len(word_limit_desc)}å•")
        print(f"  - æ–‡å­—æ•°æŒ‡å®šãªã—: {len(no_word_limit_desc)}å•")
    else:
        print("è©³ç´°ç¢ºèªãŒå¿…è¦ã§ã™")
    
    print()
    print("=== å…¨è¨­å•ä¸€è¦§ï¼ˆæœ€çµ‚ç¢ºèªç”¨ï¼‰ ===")
    print("="*40)
    for result in analysis_results:
        print(f"{result['number']}: {result['type']} ({result['details']})")
    
    total_questions = len(analysis_results)
    print(f"\nå…¨è¨­å•ç·æ•°: {total_questions}å•")
    print(f"è¨­å•æ§‹æˆ: é¸æŠ{len(choice_questions)}å• + è¨˜è¿°{total_descriptive}å• + ãã®ä»–{len(other_questions)}å• = {total_questions}å•")

def extract_document2_questions_precise(text: str) -> Dict[str, str]:
    """
    æ°¸äº•ä½³å­æ–‡ç« ã®è¨­å•ã‚’è¡Œç•ªå·ãƒ™ãƒ¼ã‚¹ã§æ­£ç¢ºã«æŠ½å‡º
    """
    questions = {}
    lines = text.split('\n')
    
    # æ°¸äº•ä½³å­é–¢é€£ã®è¨­å•é–‹å§‹è¡Œã‚’ç‰¹å®š
    doc2_start_line = None
    for i, line in enumerate(lines):
        if 'ç·šéƒ¨Aã€Œæ§˜ç›¸ã€ã€Bã€Œå¾€æ¥ã€ã€Cã€Œæ³¨åŠ›ã€' in line:
            doc2_start_line = i - 2  # ã€Œå•ä¸€ã€ã®è¡Œã‹ã‚‰é–‹å§‹
            break
    
    if doc2_start_line is None:
        print("ERROR: æ–‡ç« 2ã®è¨­å•é–‹å§‹ä½ç½®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return {}
    
    # å„å•ã‚’è¡Œãƒ™ãƒ¼ã‚¹ã§æŠ½å‡º
    current_question = None
    current_content = []
    
    for i in range(doc2_start_line, len(lines)):
        line = lines[i].strip()
        
        # è§£ç­”ç”¨ç´™ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå§‹ã¾ã£ãŸã‚‰çµ‚äº†
        if 'è§£ç­”ç”¨ç´™' in line or 'æ°å' in line:
            break
        
        # å•ä¸€ã€œå•å…«ã®é–‹å§‹ã‚’æ¤œå‡º
        if re.match(r'^å•[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«]$', line):
            # å‰ã®å•é¡Œã‚’ä¿å­˜
            if current_question:
                questions[current_question] = '\n'.join(current_content).strip()
            
            # æ–°ã—ã„å•é¡Œã‚’é–‹å§‹
            current_question = line
            current_content = []
        elif current_question:
            # ç¾åœ¨ã®å•é¡Œã®å†…å®¹ã‚’è¿½åŠ 
            current_content.append(line)
    
    # æœ€å¾Œã®å•é¡Œã‚’ä¿å­˜
    if current_question:
        questions[current_question] = '\n'.join(current_content).strip()
    
    return questions

def analyze_question_precisely(text: str) -> Dict[str, str]:
    """
    è¨­å•ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ­£ç¢ºãªã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
    """
    text_clean = text.replace('\n', ' ').replace('\r', ' ').strip()
    
    # è¨˜è¿°å•é¡Œï¼ˆæ–‡å­—æ•°æŒ‡å®šã‚ã‚Šï¼‰ã®åˆ¤å®š
    if re.search(r'äºŒåå­—ä»¥å†….*èª¬æ˜ã—ãªã•ã„', text_clean):
        return {'type': 'è¨˜è¿°ï¼ˆæ–‡å­—æ•°æŒ‡å®šã‚ã‚Šï¼‰', 'details': '20å­—ä»¥å†…è¨˜è¿°'}
    
    if re.search(r'å…«åå­—ä»¥å†….*èª¬æ˜ã—ãªã•ã„', text_clean):
        return {'type': 'è¨˜è¿°ï¼ˆæ–‡å­—æ•°æŒ‡å®šã‚ã‚Šï¼‰', 'details': '80å­—ä»¥å†…è¨˜è¿°'}
    
    if re.search(r'ä¸€è¡Œã§.*èª¬æ˜ã—ãªã•ã„', text_clean):
        return {'type': 'è¨˜è¿°ï¼ˆæ–‡å­—æ•°æŒ‡å®šã‚ã‚Šï¼‰', 'details': '1è¡Œè¨˜è¿°'}
    
    # é¸æŠå•é¡Œã®åˆ¤å®š
    if re.search(r'è¨˜å·ã§ç­”ãˆãªã•ã„', text_clean):
        # é¸æŠè‚¢æ•°ã‚’æ­£ç¢ºã«æ•°ãˆã‚‹
        katakana_choices = re.findall(r'[ã‚¢ã‚¤ã‚¦ã‚¨ã‚ªã‚«ã‚­ã‚¯ã‚±ã‚³]', text_clean)
        if katakana_choices:
            unique_choices = sorted(set(katakana_choices))
            return {'type': 'é¸æŠ', 'details': f'{len(unique_choices)}æŠé¸æŠ'}
        else:
            return {'type': 'é¸æŠ', 'details': 'é¸æŠï¼ˆæŠæ•°ä¸æ˜ï¼‰'}
    
    # è¨˜è¿°å•é¡Œï¼ˆæ–‡å­—æ•°æŒ‡å®šãªã—ï¼‰
    if re.search(r'èª¬æ˜ã—ãªã•ã„', text_clean) and not re.search(r'å­—ä»¥å†…|ä¸€è¡Œã§', text_clean):
        return {'type': 'è¨˜è¿°ï¼ˆæ–‡å­—æ•°æŒ‡å®šãªã—ï¼‰', 'details': 'è‡ªç”±è¨˜è¿°'}
    
    # æŠœãå‡ºã—å•é¡Œ
    if re.search(r'æŠœãå‡º[ã—ã›]', text_clean):
        return {'type': 'æŠœãå‡ºã—', 'details': 'æœ¬æ–‡æŠœãå‡ºã—'}
    
    # ãã®ä»–ç‰¹æ®Šãªå•é¡Œã‚¿ã‚¤ãƒ—
    if re.search(r'ç†Ÿèªã®æ§‹æˆ', text_clean):
        return {'type': 'é¸æŠ', 'details': 'ç†Ÿèªæ§‹æˆå•é¡Œ'}
    
    if re.search(r'åŒã˜è¨€è‘‰ãŒå…¥ã‚Šã¾ã™', text_clean):
        return {'type': 'é¸æŠ', 'details': 'ç©ºæ¬„è£œå……é¸æŠ'}
    
    return {'type': 'ä¸æ˜', 'details': f'åˆ†é¡å›°é›£ï¼ˆ{text_clean[:30]}...ï¼‰'}

if __name__ == '__main__':
    main()