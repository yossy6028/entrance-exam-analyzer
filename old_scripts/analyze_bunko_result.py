#!/usr/bin/env python3
"""
bunkoOCRã®çµæœã‹ã‚‰å…¥è©¦å•é¡Œã‚’åˆ†æã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
"""
import os
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
import re

def find_latest_bunko_result():
    """æœ€æ–°ã®bunkoOCRçµæœãƒ•ã‚©ãƒ«ãƒ€ã‚’è¦‹ã¤ã‘ã‚‹"""
    results_dir = Path("/Users/yoshiikatsuhiko/Library/Mobile Documents/iCloud~info~lithium03~bunkoOCR/Documents/Results")
    
    if not results_dir.exists():
        raise FileNotFoundError(f"bunkoOCRçµæœãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {results_dir}")
    
    # æœ€æ–°ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’å–å¾—
    folders = [f for f in results_dir.iterdir() if f.is_dir()]
    if not folders:
        raise FileNotFoundError("bunkoOCRçµæœãƒ•ã‚©ãƒ«ãƒ€ãŒç©ºã§ã™")
    
    latest_folder = max(folders, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“ æœ€æ–°ã®OCRçµæœãƒ•ã‚©ãƒ«ãƒ€: {latest_folder.name}")
    
    return latest_folder

def read_all_text_files(folder_path):
    """ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã™ã¹ã¦ã®text*.txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã£ã¦çµåˆ"""
    text_files = sorted(folder_path.glob("text*.txt"), key=lambda x: int(x.stem.replace('text', '')))
    
    if not text_files:
        raise FileNotFoundError(f"text*.txtãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {folder_path}")
    
    print(f"ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(text_files)}")
    
    all_text = ""
    for text_file in text_files:
        try:
            with open(text_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if content:  # ç©ºã§ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿è¿½åŠ 
                    all_text += content + "\n"
                    print(f"   âœ… {text_file.name}: {len(content)}æ–‡å­—")
                else:
                    print(f"   âš ï¸  {text_file.name}: ç©ºãƒ•ã‚¡ã‚¤ãƒ«")
        except Exception as e:
            print(f"   âŒ {text_file.name}: èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼ - {e}")
    
    return all_text

def extract_source_and_genre(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‡ºå…¸ã¨ä½œå“æƒ…å ±ã‚’æŠ½å‡º"""
    # å‡ºå…¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
    source_patterns = [
        r'(?:ä½œè€…|è‘—è€…|è©©äºº|éšç­†|å°èª¬|è©•è«–)[:ï¼š]?\s*([^\n\r]+)',
        r'ã€Œ([^ã€]+)ã€\s*([^\n\r]+(?:è‘—|ä½œ|è©©é›†|å°èª¬|éšç­†|è©•è«–))',
        r'([^\n\r]*(?:è‘—|ä½œ|è©©é›†|å°èª¬|éšç­†|è©•è«–)[^\n\r]*)',
        r'å‡ºå…¸[:ï¼š]\s*([^\n\r]+)',
    ]
    
    sources = []
    for pattern in source_patterns:
        matches = re.findall(pattern, text, re.MULTILINE)
        for match in matches:
            if isinstance(match, tuple):
                sources.extend([m.strip() for m in match if m.strip()])
            else:
                sources.append(match.strip())
    
    # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¤å®š
    genre_keywords = {
        'å°èª¬': ['å°èª¬', 'ç‰©èª', 'çŸ­ç·¨', 'é•·ç·¨'],
        'éšç­†': ['éšç­†', 'ã‚¨ãƒƒã‚»ã‚¤', 'æ—¥è¨˜', 'æ‰‹è¨˜'],
        'è©•è«–': ['è©•è«–', 'è«–æ–‡', 'æ‰¹è©•', 'è§£èª¬'],
        'è©©': ['è©©', 'è©©é›†', 'çŸ­æ­Œ', 'ä¿³å¥'],
        'å¤å…¸': ['å¤å…¸', 'æºæ°ç‰©èª', 'æ•è‰å­', 'å¾’ç„¶è‰'],
        'èª¬æ˜æ–‡': ['èª¬æ˜', 'è§£èª¬', 'æ¦‚è«–']
    }
    
    detected_genre = "ä¸æ˜"
    for genre, keywords in genre_keywords.items():
        if any(keyword in text for keyword in keywords):
            detected_genre = genre
            break
    
    return sources, detected_genre

def extract_questions(text):
    """å•é¡Œæ–‡ã‹ã‚‰è¨­å•ã‚’æŠ½å‡º"""
    # å•é¡Œç•ªå·ãƒ‘ã‚¿ãƒ¼ãƒ³
    question_patterns = [
        r'å•[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+',
        r'[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+\s*[ï¼.]',
        r'\d+\.',
        r'ï¼»\d+ï¼½'
    ]
    
    questions = []
    for pattern in question_patterns:
        matches = re.findall(pattern, text)
        questions.extend(matches)
    
    return list(set(questions))  # é‡è¤‡ã‚’é™¤å»

def analyze_difficulty(text):
    """å•é¡Œã®é›£æ˜“åº¦ã‚’åˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    # èªå½™ã®è¤‡é›‘ã•ã‚„å•é¡Œæ–‡ã®é•·ã•ãªã©ã‹ã‚‰åˆ¤å®š
    char_count = len(text)
    
    if char_count > 5000:
        return "é«˜"
    elif char_count > 2000:
        return "ä¸­"
    else:
        return "ä½"

def main():
    print("ğŸ” bunkoOCRçµæœã®åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
    
    try:
        # æœ€æ–°ã®çµæœãƒ•ã‚©ãƒ«ãƒ€ã‚’å–å¾—
        latest_folder = find_latest_bunko_result()
        
        # ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã‚Š
        full_text = read_all_text_files(latest_folder)
        
        if not full_text.strip():
            print("âŒ æœ‰åŠ¹ãªãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        print(f"\nğŸ“Š åˆ†æé–‹å§‹ - ç·æ–‡å­—æ•°: {len(full_text)}")
        
        # æƒ…å ±æŠ½å‡º
        sources, genre = extract_source_and_genre(full_text)
        questions = extract_questions(full_text)
        difficulty = analyze_difficulty(full_text)
        
        # çµæœã‚’ã¾ã¨ã‚ã‚‹
        analysis_result = {
            "å­¦æ ¡å": "é–‹æˆä¸­å­¦æ ¡",
            "å¹´åº¦": "2025",
            "ç§‘ç›®": "å›½èª",
            "å¤§å•": "1",  # ä»®å®š
            "å‡ºå…¸": "; ".join(sources) if sources else "ä¸æ˜",
            "ã‚¸ãƒ£ãƒ³ãƒ«": genre,
            "è¨­å•æ•°": len(questions),
            "é›£æ˜“åº¦": difficulty,
            "åˆ†ææ—¥æ™‚": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "æ–‡å­—æ•°": len(full_text),
            "OCRãƒ•ã‚©ãƒ«ãƒ€": latest_folder.name
        }
        
        print("\nğŸ“‹ åˆ†æçµæœ:")
        for key, value in analysis_result.items():
            print(f"   {key}: {value}")
        
        # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
        db_path = Path("entrance_exam_database.xlsx")
        
        if db_path.exists():
            print(f"\nğŸ“ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            df = pd.read_excel(db_path)
        else:
            print(f"\nğŸ“ æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆä¸­...")
            df = pd.DataFrame()
        
        # æ–°ã—ã„è¡Œã‚’è¿½åŠ 
        new_row = pd.DataFrame([analysis_result])
        df = pd.concat([df, new_row], ignore_index=True)
        
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        df.to_excel(db_path, index=False)
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜å®Œäº†: {db_path}")
        print(f"ğŸ“Š ç¾åœ¨ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df)}")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
        print(f"\nğŸ“– æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰:")
        print(full_text[:500] + "..." if len(full_text) > 500 else full_text)
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()