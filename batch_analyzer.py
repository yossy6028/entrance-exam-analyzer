#!/usr/bin/env python3
"""
å…¥è©¦å•é¡Œãƒ†ã‚­ã‚¹ãƒˆåˆ†æ ãƒãƒƒãƒå‡¦ç†ç‰ˆ
è¤‡æ•°ã®å­¦æ ¡ãƒ»å¹´åº¦ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬ã§å‡¦ç†
"""

import os
import sys
import re
import json
from pathlib import Path
from datetime import datetime
import pandas as pd
from typing import List, Dict, Tuple
import concurrent.futures
from collections import defaultdict

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(str(Path(__file__).parent))
from modules.text_analyzer import TextAnalyzer
from modules.pattern_extractor import PatternExtractor
from modules.excel_writer import ExcelWriter


class BatchAnalyzer:
    """ãƒãƒƒãƒå‡¦ç†ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼"""
    
    def __init__(self):
        # å‡¦ç†å¯¾è±¡ã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.bunko_results_dir = Path.home() / "Library/Mobile Documents/iCloud~info~lithium03~bunkoOCR/Documents/Results"
        self.kakomon_dir = Path.home() / "Desktop/01_ä»•äº‹ (Work)/ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®¶åº­æ•™å¸«è³‡æ–™/éå»å•"
        
        # å‡¦ç†çµæœã‚’æ ¼ç´
        self.results = []
        self.errors = []
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'total_files': 0,
            'processed': 0,
            'failed': 0,
            'schools': defaultdict(int),
            'years': defaultdict(int)
        }
        
    def scan_directories(self, target_dir: Path = None, pattern: str = "**/text*.txt") -> List[Dict]:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†"""
        if target_dir is None:
            target_dir = self.bunko_results_dir
            
        print(f"ğŸ“‚ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­: {target_dir}")
        file_groups = []
        
        # BunkoOCRçµæœãƒ•ã‚©ãƒ«ãƒ€ã®æ§‹é€ ã‚’è€ƒæ…®
        if target_dir == self.bunko_results_dir and target_dir.exists():
            # å„çµæœãƒ•ã‚©ãƒ«ãƒ€ã‚’ã‚°ãƒ«ãƒ¼ãƒ—ã¨ã—ã¦æ‰±ã†
            for result_folder in sorted(target_dir.iterdir(), key=lambda p: p.stat().st_mtime, reverse=True):
                if result_folder.is_dir():
                    text_files = sorted(result_folder.glob("text*.txt"))
                    if text_files:
                        # ãƒ•ã‚©ãƒ«ãƒ€åã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
                        school, year = self.extract_info_from_path(result_folder)
                        file_groups.append({
                            'files': text_files,
                            'folder': result_folder,
                            'school': school,
                            'year': year,
                            'timestamp': datetime.fromtimestamp(result_folder.stat().st_mtime)
                        })
        else:
            # é€šå¸¸ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¹ã‚­ãƒ£ãƒ³
            all_files = list(target_dir.glob(pattern))
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆåŒã˜è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®text*.txtã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰
            groups = defaultdict(list)
            for file in all_files:
                if file.name.startswith('text') and file.suffix == '.txt':
                    groups[file.parent].append(file)
                else:
                    # å˜ç‹¬ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
                    school, year = self.extract_info_from_path(file)
                    file_groups.append({
                        'files': [file],
                        'folder': file.parent,
                        'school': school,
                        'year': year,
                        'timestamp': datetime.fromtimestamp(file.stat().st_mtime)
                    })
            
            # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ 
            for folder, files in groups.items():
                school, year = self.extract_info_from_path(folder)
                file_groups.append({
                    'files': sorted(files),
                    'folder': folder,
                    'school': school,
                    'year': year,
                    'timestamp': datetime.fromtimestamp(folder.stat().st_mtime)
                })
                
        self.stats['total_files'] = len(file_groups)
        return file_groups
        
    def extract_info_from_path(self, path: Path) -> Tuple[str, str]:
        """ãƒ‘ã‚¹ã‹ã‚‰å­¦æ ¡åã¨å¹´åº¦ã‚’æŠ½å‡º"""
        path_str = str(path)
        
        # å­¦æ ¡åã®æŠ½å‡º
        school_patterns = [
            r'(é–‹æˆ|éº»å¸ƒ|æ­¦è”µ|æ¡œè”­|å¥³å­å­¦é™¢|é›™è‘‰|æ¸‹è°·æ•™è‚²å­¦åœ’æ¸‹è°·|æ¸‹æ¸‹|æ…¶æ‡‰ç¾©å¡¾|æ—©ç¨²ç”°å®Ÿæ¥­)',
            r'(\w+ä¸­å­¦æ ¡)',
            r'(\w+ä¸­ç­‰éƒ¨)',
        ]
        
        school = ""
        for pattern in school_patterns:
            match = re.search(pattern, path_str)
            if match:
                school = match.group(1)
                if 'ä¸­å­¦æ ¡' not in school and 'ä¸­ç­‰éƒ¨' not in school:
                    school += 'ä¸­å­¦æ ¡'
                break
                
        # å¹´åº¦ã®æŠ½å‡º
        year_patterns = [
            r'(20\d{2})å¹´',
            r'(20\d{2})',
            r'(\d{2})å¹´åº¦',
            r'ä»¤å’Œ(\d+)å¹´',
            r'å¹³æˆ(\d+)å¹´',
        ]
        
        year = ""
        for pattern in year_patterns:
            match = re.search(pattern, path_str)
            if match:
                if 'ä»¤å’Œ' in pattern:
                    year = str(2018 + int(match.group(1)))
                elif 'å¹³æˆ' in pattern:
                    year = str(1988 + int(match.group(1)))
                else:
                    year = match.group(1)
                    if len(year) == 2:
                        year = '20' + year
                break
                
        return school, year
        
    def process_file_group(self, file_group: Dict) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—ã‚’å‡¦ç†"""
        try:
            files = file_group['files']
            school = file_group['school']
            year = file_group['year']
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
            combined_text = ""
            for txt_file in files:
                try:
                    combined_text += txt_file.read_text(encoding='utf-8')
                    combined_text += "\n\n"
                except Exception as e:
                    print(f"  âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {txt_file.name} - {str(e)}")
                    continue
                    
            if not combined_text.strip():
                raise ValueError("ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™")
                
            # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æƒ…å ±ã‚’è£œå®Œ
            if not school or not year:
                school_from_text, year_from_text = self.extract_info_from_text(combined_text)
                school = school or school_from_text
                year = year or year_from_text
                
            if not school or not year:
                raise ValueError(f"å­¦æ ¡åã¾ãŸã¯å¹´åº¦ãŒç‰¹å®šã§ãã¾ã›ã‚“")
                
            # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
            analyzer = TextAnalyzer()
            result = analyzer.analyze_exam_structure(combined_text)
            
            # å‡ºå…¸æƒ…å ±ã‚’æŠ½å‡º
            extractor = PatternExtractor()
            sources = extractor.extract_sources(combined_text)
            
            # çµæœã‚’ã¾ã¨ã‚ã‚‹
            analysis_result = {
                'school_name': school,
                'year': year,
                'folder': str(file_group['folder']),
                'file_count': len(files),
                'timestamp': file_group['timestamp'],
                'analysis': result,
                'sources': sources,
                'status': 'success'
            }
            
            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            self.stats['processed'] += 1
            self.stats['schools'][school] += 1
            self.stats['years'][year] += 1
            
            return analysis_result
            
        except Exception as e:
            self.stats['failed'] += 1
            error_result = {
                'folder': str(file_group['folder']),
                'school_name': file_group.get('school', 'ä¸æ˜'),
                'year': file_group.get('year', 'ä¸æ˜'),
                'error': str(e),
                'status': 'failed'
            }
            self.errors.append(error_result)
            return error_result
            
    def extract_info_from_text(self, text: str) -> Tuple[str, str]:
        """ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‹ã‚‰å­¦æ ¡åã¨å¹´åº¦ã‚’æŠ½å‡º"""
        # æœ€åˆã®500æ–‡å­—ã‹ã‚‰æŠ½å‡º
        text_sample = text[:500]
        
        # å­¦æ ¡åã®æŠ½å‡º
        school_patterns = [
            r'(é–‹æˆ|éº»å¸ƒ|æ­¦è”µ|æ¡œè”­|å¥³å­å­¦é™¢|é›™è‘‰|æ¸‹è°·æ•™è‚²å­¦åœ’æ¸‹è°·|æ¸‹æ¸‹|æ…¶æ‡‰ç¾©å¡¾|æ—©ç¨²ç”°å®Ÿæ¥­)',
            r'(\w+ä¸­å­¦æ ¡)',
            r'(\w+ä¸­ç­‰éƒ¨)',
        ]
        
        school = ""
        for pattern in school_patterns:
            match = re.search(pattern, text_sample)
            if match:
                school = match.group(1)
                if 'ä¸­å­¦æ ¡' not in school and 'ä¸­ç­‰éƒ¨' not in school:
                    school += 'ä¸­å­¦æ ¡'
                break
                
        # å¹´åº¦ã®æŠ½å‡º
        year_patterns = [
            r'(20\d{2})å¹´',
            r'(\d{2})å¹´åº¦',
            r'ä»¤å’Œ(\d+)å¹´',
            r'å¹³æˆ(\d+)å¹´',
        ]
        
        year = ""
        for pattern in year_patterns:
            match = re.search(pattern, text_sample)
            if match:
                if 'ä»¤å’Œ' in pattern:
                    year = str(2018 + int(match.group(1)))
                elif 'å¹³æˆ' in pattern:
                    year = str(1988 + int(match.group(1)))
                else:
                    year = match.group(1)
                    if len(year) == 2:
                        year = '20' + year
                break
                
        return school, year
        
    def save_to_database(self, results: List[Dict]):
        """å‡¦ç†çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        db_filename = "entrance_exam_database.xlsx"
        
        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        try:
            existing_sheets = pd.ExcelFile(db_filename, engine='openpyxl').sheet_names
        except FileNotFoundError:
            existing_sheets = []
            
        # å­¦æ ¡åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        school_data = defaultdict(list)
        for result in results:
            if result['status'] == 'success':
                school_name = result['school_name']
                data_row = self.prepare_data_row(result)
                school_data[school_name].append(data_row)
                
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with pd.ExcelWriter(db_filename, engine='openpyxl', 
                           mode='a' if existing_sheets else 'w', 
                           if_sheet_exists='replace') as writer:
            for school_name, rows in school_data.items():
                new_df = pd.DataFrame(rows)
                
                if school_name in existing_sheets:
                    # æ—¢å­˜ã‚·ãƒ¼ãƒˆã«è¿½åŠ 
                    existing_df = pd.read_excel(db_filename, sheet_name=school_name)
                    existing_df['å¹´åº¦'] = pd.to_numeric(existing_df['å¹´åº¦'], errors='coerce')
                    
                    # é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®å¹´åº¦ã§æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
                    years_to_update = new_df['å¹´åº¦'].unique()
                    existing_df = existing_df[~existing_df['å¹´åº¦'].isin(years_to_update)]
                    
                    combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                    combined_df = combined_df.sort_values('å¹´åº¦')
                else:
                    combined_df = new_df.sort_values('å¹´åº¦')
                    
                combined_df.to_excel(writer, sheet_name=school_name, index=False)
                
    def prepare_data_row(self, result: Dict) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç”¨ã®ãƒ‡ãƒ¼ã‚¿è¡Œã‚’æº–å‚™"""
        analysis = result['analysis']
        sources = result['sources']
        
        data_row = {
            'å¹´åº¦': int(result['year']),
            'ç·è¨­å•æ•°': len(analysis.get('questions', [])),
            'ç·æ–‡å­—æ•°': analysis.get('total_characters', 0),
            'å¤§å•æ•°': len(analysis.get('sections', [])),
            'å‡¦ç†æ—¥æ™‚': result['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
            'ãƒ•ã‚¡ã‚¤ãƒ«æ•°': result['file_count']
        }
        
        # å„å¤§å•ã®ãƒ‡ãƒ¼ã‚¿
        for i, section in enumerate(analysis.get('sections', []), 1):
            # ã‚¸ãƒ£ãƒ³ãƒ«ã¨ãƒ†ãƒ¼ãƒã‚’åˆ¤å®š
            genre, theme = self.determine_genre_and_theme(section.get('text', ''))
            
            # å‡ºå…¸æƒ…å ±ã‚’å–å¾—
            source = next((s for s in sources if s.get('section') == i), {})
            
            data_row[f'å¤§å•{i}_ã‚¸ãƒ£ãƒ³ãƒ«'] = genre
            data_row[f'å¤§å•{i}_ãƒ†ãƒ¼ãƒ'] = theme
            data_row[f'å¤§å•{i}_è‘—è€…'] = source.get('author', 'ä¸æ˜')
            data_row[f'å¤§å•{i}_ä½œå“'] = source.get('title', 'ä¸æ˜')
            data_row[f'å¤§å•{i}_è¨­å•æ•°'] = section.get('question_count', 0)
            data_row[f'å¤§å•{i}_æ–‡å­—æ•°'] = len(section.get('text', ''))
            
        # è¨­å•ã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ
        for q_type, count in analysis.get('question_types', {}).items():
            data_row[f'{q_type}_å•é¡Œæ•°'] = count
            
        return data_row
        
    def determine_genre_and_theme(self, text: str) -> Tuple[str, str]:
        """æ–‡ç« ã®ã‚¸ãƒ£ãƒ³ãƒ«ã¨ãƒ†ãƒ¼ãƒã‚’åˆ¤å®š"""
        text_sample = text[:1000] if len(text) > 1000 else text
        
        # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¤å®š
        if any(word in text_sample for word in ['å°èª¬', 'ç‰©èª', 'ã€Œ', 'ã€', 'ã¨è¨€ã£ãŸ']):
            genre = 'å°èª¬ãƒ»ç‰©èª'
        elif any(word in text_sample for word in ['è©•è«–', 'è«–èª¬', 'ã«ã¤ã„ã¦', 'ã¨ã„ã†']):
            genre = 'è©•è«–ãƒ»è«–èª¬'
        elif any(word in text_sample for word in ['éšç­†', 'ã‚¨ãƒƒã‚»ã‚¤', 'ç§ã¯']):
            genre = 'éšç­†ãƒ»ã‚¨ãƒƒã‚»ã‚¤'
        else:
            genre = 'è©•è«–ãƒ»è«–èª¬'
            
        # ãƒ†ãƒ¼ãƒåˆ¤å®š
        if any(word in text_sample for word in ['å‹æƒ…', 'å®¶æ—', 'æˆé•·']):
            theme = 'äººé–“é–¢ä¿‚ãƒ»æˆé•·'
        elif any(word in text_sample for word in ['è‡ªç„¶', 'ç’°å¢ƒ', 'ç”Ÿç‰©']):
            theme = 'è‡ªç„¶ãƒ»ç’°å¢ƒ'
        elif any(word in text_sample for word in ['ç¤¾ä¼š', 'æ–‡åŒ–', 'æ­´å²']):
            theme = 'ç¤¾ä¼šãƒ»æ–‡åŒ–'
        elif any(word in text_sample for word in ['ç§‘å­¦', 'æŠ€è¡“', 'AI']):
            theme = 'ç§‘å­¦ãƒ»æŠ€è¡“'
        else:
            theme = 'ä¸€èˆ¬'
            
        return genre, theme
        
    def generate_summary_report(self):
        """å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report_filename = f"batch_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("å…¥è©¦å•é¡Œåˆ†æ ãƒãƒƒãƒå‡¦ç†ãƒ¬ãƒãƒ¼ãƒˆ\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"å‡¦ç†æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å‡¦ç†å¯¾è±¡: {self.stats['total_files']}ä»¶\n")
            f.write(f"æˆåŠŸ: {self.stats['processed']}ä»¶\n")
            f.write(f"å¤±æ•—: {self.stats['failed']}ä»¶\n")
            f.write(f"æˆåŠŸç‡: {self.stats['processed'] / self.stats['total_files'] * 100:.1f}%\n\n")
            
            f.write("ã€å­¦æ ¡åˆ¥å‡¦ç†ä»¶æ•°ã€‘\n")
            for school, count in sorted(self.stats['schools'].items()):
                f.write(f"  {school}: {count}ä»¶\n")
                
            f.write("\nã€å¹´åº¦åˆ¥å‡¦ç†ä»¶æ•°ã€‘\n")
            for year, count in sorted(self.stats['years'].items()):
                f.write(f"  {year}å¹´: {count}ä»¶\n")
                
            if self.errors:
                f.write("\nã€ã‚¨ãƒ©ãƒ¼è©³ç´°ã€‘\n")
                for error in self.errors:
                    f.write(f"\nãƒ•ã‚©ãƒ«ãƒ€: {error['folder']}\n")
                    f.write(f"å­¦æ ¡: {error['school_name']}\n")
                    f.write(f"å¹´åº¦: {error['year']}\n")
                    f.write(f"ã‚¨ãƒ©ãƒ¼: {error['error']}\n")
                    f.write("-" * 40 + "\n")
                    
        return report_filename
        
    def run_batch_processing(self, target_dir: Path = None, parallel: bool = True, max_workers: int = 4):
        """ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œ"""
        print("ğŸš€ ãƒãƒƒãƒå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...\n")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³
        file_groups = self.scan_directories(target_dir)
        
        if not file_groups:
            print("âŒ å‡¦ç†å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
            
        print(f"ğŸ“Š {len(file_groups)}å€‹ã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\n")
        
        # å‡¦ç†ã‚’å®Ÿè¡Œ
        if parallel:
            print(f"âš¡ ä¸¦åˆ—å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆæœ€å¤§{max_workers}ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼‰\n")
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = []
                for i, file_group in enumerate(file_groups, 1):
                    future = executor.submit(self.process_file_group, file_group)
                    futures.append((i, file_group, future))
                    
                for i, file_group, future in futures:
                    try:
                        result = future.result(timeout=60)  # 1åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                        self.results.append(result)
                        
                        status = "âœ…" if result['status'] == 'success' else "âŒ"
                        print(f"{status} [{i}/{len(file_groups)}] {result['school_name']} {result['year']}å¹´")
                        
                    except concurrent.futures.TimeoutError:
                        print(f"â±ï¸  [{i}/{len(file_groups)}] ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {file_group['folder']}")
                        self.stats['failed'] += 1
                    except Exception as e:
                        print(f"âŒ [{i}/{len(file_groups)}] ã‚¨ãƒ©ãƒ¼: {str(e)}")
                        self.stats['failed'] += 1
        else:
            print("ğŸ”„ é€æ¬¡å‡¦ç†ãƒ¢ãƒ¼ãƒ‰\n")
            for i, file_group in enumerate(file_groups, 1):
                result = self.process_file_group(file_group)
                self.results.append(result)
                
                status = "âœ…" if result['status'] == 'success' else "âŒ"
                print(f"{status} [{i}/{len(file_groups)}] {result.get('school_name', 'ä¸æ˜')} {result.get('year', 'ä¸æ˜')}å¹´")
                
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        if self.results:
            print("\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ä¸­...")
            self.save_to_database(self.results)
            
        # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        print("\nğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
        report_file = self.generate_summary_report()
        
        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        print("\n" + "=" * 60)
        print("âœ… ãƒãƒƒãƒå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("=" * 60)
        print(f"å‡¦ç†ä»¶æ•°: {self.stats['processed']}/{self.stats['total_files']}")
        print(f"ã‚¨ãƒ©ãƒ¼ä»¶æ•°: {self.stats['failed']}")
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: entrance_exam_database.xlsx")
        print(f"ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
        print("=" * 60)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å…¥è©¦å•é¡Œãƒ†ã‚­ã‚¹ãƒˆåˆ†æ ãƒãƒƒãƒå‡¦ç†')
    parser.add_argument('--dir', type=str, help='å‡¦ç†å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: BunkoOCRçµæœãƒ•ã‚©ãƒ«ãƒ€ï¼‰')
    parser.add_argument('--sequential', action='store_true', help='é€æ¬¡å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä¸¦åˆ—å‡¦ç†ï¼‰')
    parser.add_argument('--workers', type=int, default=4, help='ä¸¦åˆ—å‡¦ç†æ™‚ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 4ï¼‰')
    parser.add_argument('--kakomon', action='store_true', help='éå»å•ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‡¦ç†å¯¾è±¡ã«ã™ã‚‹')
    
    args = parser.parse_args()
    
    # ãƒãƒƒãƒã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’åˆæœŸåŒ–
    analyzer = BatchAnalyzer()
    
    # å‡¦ç†å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ±ºå®š
    if args.dir:
        target_dir = Path(args.dir)
    elif args.kakomon:
        target_dir = analyzer.kakomon_dir
    else:
        target_dir = None  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆBunkoOCRçµæœãƒ•ã‚©ãƒ«ãƒ€ï¼‰
        
    # ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œ
    analyzer.run_batch_processing(
        target_dir=target_dir,
        parallel=not args.sequential,
        max_workers=args.workers
    )


if __name__ == "__main__":
    main()